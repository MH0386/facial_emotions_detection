{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:33.813523Z",
     "iopub.status.busy": "2023-07-25T17:32:33.813063Z",
     "iopub.status.idle": "2023-07-25T17:32:33.823764Z",
     "shell.execute_reply": "2023-07-25T17:32:33.822594Z",
     "shell.execute_reply.started": "2023-07-25T17:32:33.813487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:33.856871Z",
     "iopub.status.busy": "2023-07-25T17:32:33.856532Z",
     "iopub.status.idle": "2023-07-25T17:32:33.863955Z",
     "shell.execute_reply": "2023-07-25T17:32:33.862902Z",
     "shell.execute_reply.started": "2023-07-25T17:32:33.856841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToLocal = \"images/validation/\"\n",
    "pathToKaggle = \"/kaggle/input/face-expression-recognition-dataset/images/validation/\"\n",
    "\n",
    "path = pathToLocal if os.path.exists(pathToLocal) else pathToKaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:33.867117Z",
     "iopub.status.busy": "2023-07-25T17:32:33.866398Z",
     "iopub.status.idle": "2023-07-25T17:32:34.361979Z",
     "shell.execute_reply": "2023-07-25T17:32:34.360993Z",
     "shell.execute_reply.started": "2023-07-25T17:32:33.867084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for i, expression in enumerate(path, start=1):\n",
    "    img = load_img(f\"images/validation/{expression}/{os.listdir(f'images/validation/{expression}')[0]}\")\n",
    "    plt.subplot(1, 7, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(expression)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the amount of data in each folder in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:34.364825Z",
     "iopub.status.busy": "2023-07-25T17:32:34.363243Z",
     "iopub.status.idle": "2023-07-25T17:32:34.388176Z",
     "shell.execute_reply": "2023-07-25T17:32:34.387281Z",
     "shell.execute_reply.started": "2023-07-25T17:32:34.364786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for expression in os.listdir(\"images/train/\"):\n",
    "        print(\n",
    "            expression,\n",
    "            \"folder contains\\t\\t\",\n",
    "            len(os.listdir(\"images/train/\" + expression)),\n",
    "            \"images\",\n",
    "        )\n",
    "except:\n",
    "    for expression in os.listdir(\n",
    "            \"/kaggle/input/face-expression-recognition-dataset/images/train/\"\n",
    "    ):\n",
    "        print(\n",
    "            expression,\n",
    "            \"folder contains\\t\\t\",\n",
    "            len(\n",
    "                os.listdir(\n",
    "                    \"/kaggle/input/face-expression-recognition-dataset/images/train/\"\n",
    "                    + expression\n",
    "                )\n",
    "            ),\n",
    "            \"images\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the amount of data in each folder in testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:34.390505Z",
     "iopub.status.busy": "2023-07-25T17:32:34.390222Z",
     "iopub.status.idle": "2023-07-25T17:32:34.404139Z",
     "shell.execute_reply": "2023-07-25T17:32:34.403223Z",
     "shell.execute_reply.started": "2023-07-25T17:32:34.390480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for expression in os.listdir(\"images/validation/\"):\n",
    "        print(\n",
    "            expression,\n",
    "            \"folder contains\\t\\t\",\n",
    "            len(os.listdir(\"images/validation/\" + expression)),\n",
    "            \"images\",\n",
    "        )\n",
    "except:\n",
    "    for expression in os.listdir(\n",
    "            \"/kaggle/input/face-expression-recognition-dataset/images/validation/\"\n",
    "    ):\n",
    "        print(\n",
    "            expression,\n",
    "            \"folder contains\\t\\t\",\n",
    "            len(\n",
    "                os.listdir(\n",
    "                    \"/kaggle/input/face-expression-recognition-dataset/images/validation/\"\n",
    "                    + expression\n",
    "                )\n",
    "            ),\n",
    "            \"images\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:34.406259Z",
     "iopub.status.busy": "2023-07-25T17:32:34.405822Z",
     "iopub.status.idle": "2023-07-25T17:32:34.534127Z",
     "shell.execute_reply": "2023-07-25T17:32:34.533350Z",
     "shell.execute_reply.started": "2023-07-25T17:32:34.406225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(48, 48, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l1()),\n",
    "        Dropout(0.5),\n",
    "        Dense(7, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l1()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:34.535616Z",
     "iopub.status.busy": "2023-07-25T17:32:34.535182Z",
     "iopub.status.idle": "2023-07-25T17:32:40.538703Z",
     "shell.execute_reply": "2023-07-25T17:32:40.537624Z",
     "shell.execute_reply.started": "2023-07-25T17:32:34.535558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    datagen_train = ImageDataGenerator(\n",
    "        rescale=1.0 / 255, zoom_range=0.3, horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = datagen_train.flow_from_directory(\n",
    "        \"/kaggle/input/face-expression-recognition-dataset/images/train/\",\n",
    "        batch_size=64,\n",
    "        target_size=(48, 48),\n",
    "        shuffle=True,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    datagen_test = ImageDataGenerator(\n",
    "        rescale=1.0 / 255, zoom_range=0.3, horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    test_generator = datagen_test.flow_from_directory(\n",
    "        \"/kaggle/input/face-expression-recognition-dataset/images/validation/\",\n",
    "        batch_size=64,\n",
    "        target_size=(48, 48),\n",
    "        shuffle=True,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "except:\n",
    "    datagen_train = ImageDataGenerator(\n",
    "        rescale=1.0 / 255, zoom_range=0.3, horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = datagen_train.flow_from_directory(\n",
    "        \"images/train/\",\n",
    "        batch_size=64,\n",
    "        target_size=(48, 48),\n",
    "        shuffle=True,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    datagen_test = ImageDataGenerator(\n",
    "        rescale=1.0 / 255, zoom_range=0.3, horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    test_generator = datagen_test.flow_from_directory(\n",
    "        \"images/validation/\",\n",
    "        batch_size=64,\n",
    "        target_size=(48, 48),\n",
    "        shuffle=True,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "steps_per_epoch = train_generator.n / train_generator.batch_size\n",
    "testing_steps = test_generator.n / test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = np.array(train_generator)\n",
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T17:32:40.540723Z",
     "iopub.status.busy": "2023-07-25T17:32:40.540240Z",
     "iopub.status.idle": "2023-07-25T19:16:49.938685Z",
     "shell.execute_reply": "2023-07-25T19:16:49.937680Z",
     "shell.execute_reply.started": "2023-07-25T17:32:40.540685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=train_generator, epochs=100, validation_split=0.2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=test_generator, steps=testing_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the training and validation accuracy and loss at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-25T19:16:49.940946Z",
     "iopub.status.busy": "2023-07-25T19:16:49.940262Z",
     "iopub.status.idle": "2023-07-25T19:16:50.297499Z",
     "shell.execute_reply": "2023-07-25T19:16:50.296490Z",
     "shell.execute_reply.started": "2023-07-25T19:16:49.940908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"y\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
